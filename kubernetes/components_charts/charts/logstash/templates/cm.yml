#################### gerneral config: dir, limit, etc ##########
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-general-config
data:
  logstash.yml: |
    # path.data: /var/lib/logstash
    pipeline.workers: 1
    api.enabled: true
    api.http.host: 0.0.0.0
    api.http.port: 9600
    api.auth.type: basic
    api.auth.basic.username: "logstash"
    api.auth.basic.password: "juniper@123"
    path.logs: /var/log/logstash
    monitoring.enabled: false #true #false
    monitoring.cluster_uuid: -v_1z88WS4OnMeaF7kpVWA

  jvm.options: |
    ## JVM configuration

    # Xms represents the initial size of total heap space
    # Xmx represents the maximum size of total heap space

    # -Xms3g
    # -Xmx3g
    -Xms{{.Values.heapSize}}
    -Xmx{{.Values.heapSize}}

    ################################################################
    ## Expert settings
    ################################################################
    ##
    ## All settings below this section are considered
    ## expert settings. Don't tamper with them unless
    ## you understand what you are doing
    ##
    ################################################################

    ## GC configuration
    11-13:-XX:+UseConcMarkSweepGC
    11-13:-XX:CMSInitiatingOccupancyFraction=75
    11-13:-XX:+UseCMSInitiatingOccupancyOnly

    ## Locale
    # Set the locale language
    #-Duser.language=en

    # Set the locale country
    #-Duser.country=US

    # Set the locale variant, if any
    #-Duser.variant=

    ## basic

    # set the I/O temp directory
    #-Djava.io.tmpdir=$HOME

    # set to headless, just in case
    -Djava.awt.headless=true

    # ensure UTF-8 encoding by default (e.g. filenames)
    -Dfile.encoding=UTF-8

    # use our provided JNA always versus the system one
    #-Djna.nosys=true

    # Turn on JRuby invokedynamic
    -Djruby.compile.invokedynamic=true
    # Force Compilation
    -Djruby.jit.threshold=0
    # Make sure joni regexp interruptability is enabled
    -Djruby.regexp.interruptible=true

    ## heap dumps

    # generate a heap dump when an allocation from the Java heap fails
    # heap dumps are created in the working directory of the JVM
    -XX:+HeapDumpOnOutOfMemoryError

    # specify an alternative path for heap dumps
    # ensure the directory exists and has sufficient space
    #-XX:HeapDumpPath=${LOGSTASH_HOME}/heapdump.hprof

    ## GC logging
    #-Xlog:gc*,gc+age=trace,safepoint:file=@loggc@:utctime,pid,tags:filecount=32,filesize=64m

    # log GC status to a file with time stamps
    # ensure the directory exists
    #-Xloggc:${LS_GC_LOG_FILE}

    # Entropy source for randomness
    -Djava.security.egd=file:/dev/urandom

    # Copy the logging context from parent threads to children
    -Dlog4j2.isThreadContextMapInheritable=true
  startup.options: |
    ################################################################################
    # These settings are ONLY used by $LS_HOME/bin/system-install to create a custom
    # startup script for Logstash and is not used by Logstash itself. It should
    # automagically use the init system (systemd, upstart, sysv, etc.) that your
    # Linux distribution uses.
    #
    # After changing anything here, you need to re-run $LS_HOME/bin/system-install
    # as root to push the changes to the init script.
    ################################################################################

    # Override Java location
    #JAVACMD=/usr/bin/java

    # Set a home directory
    LS_HOME=/usr/share/logstash

    # logstash settings directory, the path which contains logstash.yml
    LS_SETTINGS_DIR=/etc/logstash

    # Arguments to pass to logstash
    LS_OPTS="--path.settings ${LS_SETTINGS_DIR}"

    # Arguments to pass to java
    LS_JAVA_OPTS=""

    # pidfiles aren't used the same way for upstart and systemd; this is for sysv users.
    LS_PIDFILE=/var/run/logstash.pid

    # user and group id to be invoked as
    LS_USER=logstash
    LS_GROUP=logstash

    # Enable GC logging by uncommenting the appropriate lines in the GC logging
    # section in jvm.options
    LS_GC_LOG_FILE=/var/log/logstash/gc.log

    # Open file limit
    LS_OPEN_FILES=16384

    # Nice level
    LS_NICE=19

    # Change these to have the init script named and described differently
    # This is useful when running multiple instances of Logstash on the same
    # physical box or vm
    SERVICE_NAME="logstash"
    SERVICE_DESCRIPTION="logstash"

    # If you need to run a command or script before launching Logstash, put it
    # between the lines beginning with `read` and `EOM`, and uncomment those lines.
    ###
    ## read -r -d '' PRESTART << EOM
    ## EOM

  pipelines.yml: |
    - pipeline.id: svtechlab
      pipeline.ecs_compatibility: disabled
      path.config: "/etc/logstash/conf.d/svtech-lab-online/jun-svtechlab-onlinelog.conf"

    - pipeline.id: offline
      pipeline.ecs_compatibility: disabled
      path.config: "/etc/logstash/conf.d/offline/offline-log.conf"

################### pattern config #############################
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-patterns
data:
  junos_fpc: |
    PRIORITYCODE (?<=\<)[0-9]{1,}(?=\>)
    TIMESTAMP_ISO8601 %{YEAR}-%{MONTHNUM}-%{MONTHDAY}[T ]%{HOUR}:?%{MINUTE}(?::?%{SECOND})?%{ISO8601_TIMEZONE}?
    JUNHOSTNAME [a-zA-Z0-9\_\-\[\.]{1,}
    FPCNAME [a-z0-9]{1,}
    MESSAGE (?<=\s).*

  junos_off_chassisd: |
    DATESTAMP_FULL %{MONTH} %{MONTHDAY} %{TIME} %{YEAR}
    DATESTAMP_FULL2 %{MONTH}  %{MONTHDAY} %{TIME} %{YEAR}
    DATESTAMP_NOTYEAR %{MONTH} %{MONTHDAY} %{TIME}
    CHASSISPROC [a-zA-Z0-9\_\-\[]{1,}
    CHASSISEVENT [a-zA-Z0-9\_\-\[]{1,}
    MESSAGE .*

  junos_off_chassisd_snmp: |
    DATESTAMP_FULL %{MONTH} %{MONTHDAY} %{TIME} %{YEAR}
    DATESTAMP_FULL2 %{MONTH}  %{MONTHDAY} %{TIME} %{YEAR}
    DATESTAMP_NOTYEAR %{MONTH} %{MONTHDAY} %{TIME}
    CHASSISPROC [a-zA-Z0-9\_\-\[]{1,}
    MESSAGE .*

  junos_off_config-changes: |
    DATESTAMP_FULL %{MONTH} %{MONTHDAY} %{TIME} %{YEAR}
    DATESTAMP_FULL2 %{MONTH}  %{MONTHDAY} %{TIME} %{YEAR}
    DATESTAMP_NOTYEAR %{MONTH} %{MONTHDAY} %{TIME}
    JUNHOSTNAME [a-zA-Z0-9\_\-\[\.]{1,}
    PROCESSNAME [a-zA-Z0-9\/\:\_\-\.]{1,}
    PROCESSID [0-9_]{1,}
    EVENTNAME [A-Z0-9\_]{1,}
    USER [a-z]{1,}
    COMMAND [a-z]{1,}
    MESSAGE .*

  junos_off_interactive-commands: |
    DATESTAMP_FULL %{MONTH} %{MONTHDAY} %{TIME} %{YEAR}
    DATESTAMP_FULL2 %{MONTH}  %{MONTHDAY} %{TIME} %{YEAR}
    DATESTAMP_NOTYEAR %{MONTH} %{MONTHDAY} %{TIME}
    JUNHOSTNAME [a-zA-Z0-9\_\-\[\.]{1,}
    PROCESSNAME [a-zA-Z0-9\/\:\_\-\.]{1,}
    PROCESSID [0-9_]{1,}
    EVENTNAME [A-Z0-9\_]{1,}
    MESSAGE .*

  junos_off_message: |
    DATESTAMP_FULL %{MONTH} %{MONTHDAY} %{TIME} %{YEAR}
    DATESTAMP_FULL2 %{MONTH}  %{MONTHDAY} %{TIME} %{YEAR}
    DATESTAMP_NOTYEAR %{MONTH} %{MONTHDAY} %{TIME}
    JUNHOSTNAME [a-zA-Z0-9\_\-\[\.]{1,}
    PROCESSNAME [a-zA-Z0-9\/\:\_\-\.]{1,}
    PROCESSID (?<=\[)[0-9_]{1,}
    FACILITYNAME [a-zA-Z]{1,}
    SEVERITYCODE [0-9_]{1,}
    EVENTNAME [a-zA-Z0-9\_]{1,}
    MESSAGE (?<=\:\s).*

  junos_off_security: |
    DATESTAMP_FULL %{MONTH} %{MONTHDAY} %{TIME} %{YEAR}
    DATESTAMP_FULL2 %{MONTH}  %{MONTHDAY} %{TIME} %{YEAR}
    DATESTAMP_NOTYEAR %{MONTH} %{MONTHDAY} %{TIME}
    JUNHOSTNAME [a-zA-Z0-9\_\-\[\.]{1,}
    PROCESSNAME [a-zA-Z0-9\/\:\_\-\.]{1,}
    PROCESSID [0-9_]{1,}
    EVENTNAME [a-zA-Z0-9\_]{1,}
    MESSAGE1 (?<=\s).*
    MESSAGE2 (?<=\:\s).*

  junos_offlog_explicit_priority: |
    DATESTAMP_FULL %{MONTH}%{SPACE}%{MONTHDAY}%{SPACE}%{TIME}%{SPACE}%{YEAR}
    DATESTAMP_NOTYEAR %{MONTH}%{SPACE}%{MONTHDAY}%{SPACE}%{TIME}
    JUNHOSTNAME [a-zA-Z0-9\_\-\[\.]{1,}
    PROCESSNAME [a-zA-Z0-9\/\:\_\-\.]{1,}
    PROCESSID (?<=\[)[0-9_]{1,}
    FACILITYNAME [a-zA-Z]{1,}
    SEVERITYCODE [0-9_]{1,}
    EVENTNAME [a-zA-Z0-9\_\(\)]{1,}
    MESSAGE (?<=\:\s).*

  junos_offlog_unstructured_log: |
    DATESTAMP_FULL %{MONTH}%{SPACE}%{MONTHDAY}%{SPACE}%{TIME}%{SPACE}%{YEAR}
    DATESTAMP_NOTYEAR %{MONTH}%{SPACE}%{MONTHDAY}%{SPACE}%{TIME}
    JUNHOSTNAME [a-zA-Z0-9\_\-\[\.]{1,}
    PROCESSNAME [a-zA-Z0-9\/\:\_\-\.]{1,}
    PROCESSID (?<=\[)[0-9_]{1,}
    FACILITYNAME [a-zA-Z]{1,}
    SEVERITYCODE [0-9_]{1,}
    EVENTNAME [a-zA-Z0-9\_\(\)]{1,}
    MESSAGE (?<=\:\s).*
    FPCNAME [Ff][Pp][Cc][0-9]{1,2}

  offlog_explicit_priority: |
    DATESTAMP_FULL %{MONTH}%{SPACE}%{MONTHDAY}%{SPACE}%{TIME}%{SPACE}%{YEAR}
    DATESTAMP_NOTYEAR %{MONTH}%{SPACE}%{MONTHDAY}%{SPACE}%{TIME}
    JUNHOSTNAME [a-zA-Z0-9\_\-\[\.]{1,}
    PROCESSNAME [a-zA-Z0-9\/\:\_\-\.]{1,}
    PROCESSID (?<=\[)[0-9_]{1,}
    FACILITYNAME [a-zA-Z]{1,}
    SEVERITYCODE [0-9_]{1,}
    EVENTNAME [a-zA-Z0-9\_\(\)]{1,}
    MESSAGE (?<=\:\s).*
  offlog_unstructured_log: |
    DATESTAMP_FULL %{MONTH}%{SPACE}%{MONTHDAY}%{SPACE}%{TIME}%{SPACE}%{YEAR}
    DATESTAMP_NOTYEAR %{MONTH}%{SPACE}%{MONTHDAY}%{SPACE}%{TIME}
    JUNHOSTNAME [a-zA-Z0-9\_\-\[\.]{1,}
    PROCESSNAME [a-zA-Z0-9\/\:\_\-\.]{1,}
    PROCESSID (?<=\[)[0-9_]{1,}
    FACILITYNAME [a-zA-Z]{1,}
    SEVERITYCODE [0-9_]{1,}
    EVENTNAME [a-zA-Z0-9\_\(\)]{1,}
    MESSAGE (?<=\:\s).*

  radius_log: |
    RAS_DATE %{MONTHNUM}/%{MONTHDAY}/%{YEAR}
    RAS_HOUR %{HOUR}:?%{MINUTE}(?::?%{SECOND})?

  structured_log: |
    PRIORITYCODE (?<=\<)[0-9]{1,}(?=\>)
    TIMESTAMP_ISO8601 %{YEAR}-%{MONTHNUM}-%{MONTHDAY}[T ]%{HOUR}:?%{MINUTE}(?::?%{SECOND})?%{ISO8601_TIMEZONE}?
    JUNHOSTNAME [a-zA-Z0-9\_\-\.]{1,}
    PROCESSNAME [a-zA-Z0-9\/\:\_\.\-]{1,}
    PROCESSID [0-9_]{1,}
    EVENTNAME [a-zA-Z0-9\_\-\"]{1,}
    SNMPINFO ((?<=\[).*(?=\]))
    MESSAGE .*

################### dictionary config #############################
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: logstash-dictionary
data:
  client_mode.yml: |
    ---
    - "cli": "ssh"
    - "tty*": "telnet"
    - "netconf": "netconf"
    - "junoscript*": "junoscript"
    - "pts*": "telnet"

  facilitycode.yml: |
    ---
    - "0": "KERNEL"
    - "1": "USER"
    - "2": "MAIL"
    - "3": "DAEMON"
    - "4": "AUTHORIZATION"
    - "5": "SYSLOG"
    - "6": "PRINTER"
    - "7": "NEWS"
    - "8": "UUCP"
    - "9": "CLOCK"
    - "10": "AUTHORIZATION-PRIVATE"
    - "11": "FTP"
    - "12": "NTP"
    - "13": "SECURITY"
    - "14": "CONSOLE"
    - "16": "LOCAL0"
    - "17": "DFC"
    - "18": "LOCAL2"
    - "19": "FIREWALL"
    - "20": "PFE"
    - "21": "CONFLICT-LOG"
    - "22": "CHANGE-LOG"
    - "23": "INTERACTIVE-COMMANDS"

  severitycode.yml: |
    ---
    - "0": "EMERGENCY"
    - "1": "ALERT"
    - "2": "CRITICAL"
    - "3": "ERROR"
    - "4": "WARNING"
    - "5": "NOTICE"
    - "6": "INFO"
    - "7": "ANY"

  timezone.yml: |
    ---
    - "movitel": "Africa/Tripoli"
    - "unitel": "Asia/Vientiane"
    - "metfone": "Asia/Phnom_Penh"
    - "vnpt": "Asia/Ho_Chi_Minh"
    - "mobifone": "Asia/Ho_Chi_Minh"
    - "natcom": "America/Aruba"


################### pipeline config #############################

################### svtech-lab device management pipeline config ###################
{{- $clusterName := .Values.global.elasticsearch.clusterName -}}
{{- $newArray := list -}}
{{- range .Values.global.elasticsearch.nodes -}}
  {{- $newArray = append $newArray (printf "%s-es-%s" $clusterName .name) -}}
{{- end -}}
{{ $newArray }}

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: online-log
data:
  jun-svtechlab-onlinelog.conf: |
    input {
      tcp {
        port => 5515
        type => syslog
        tags => junos_log
      }
      udp {
        port => 5515
        type => syslog
        tags => junos_log
      }
    }

    filter {
      if "junos_log" in [tags] {
        mutate {
          add_field => [ "received_at", "%{@timestamp}" ]
          add_field => [ "received_from", "%{host}" ]
        }
        if ([message] =~ /nginx health check/) {
            drop {}
        }
        if ([message] =~ /haproxy/) {
            drop {}
        }
        if ([message] =~ /username=\"icinga\"/) {
            drop {}
        }
        if [message] =~ "- - - - fpc" {
            drop {}
        }
        else {
          grok {
            match => { "message" => "<%{PRIORITYCODE:junos_priocode}>1 %{TIMESTAMP_ISO8601:junos_time} %{JUNHOSTNAME:junos_hostname} (%{PROCESSNAME:junos_procsname}|\-) (%{PROCESSID:junos_procsid}|\-) (%{EVENTNAME:junos_eventname}|\-) %{MESSAGE:junos_msg}" }
            patterns_dir => ["/etc/logstash/patterns"]
            patterns_files_glob => "structured_log"
          }
        }

        mutate {
          convert => { "junos_priocode" => "integer" }
        }
        ruby {
          code => 'event.set("junos_facilitycode", event.get("junos_priocode")/8)'
        }
        ruby {
          code => 'event.set("junos_severitycode", event.get("junos_priocode")%8)'
        }
        translate {
          field => "[junos_severitycode]"
          destination => "[junos_severityname]"
          # dictionary_path => "/etc/logstash/dictionary/facilitycode.yml"
          dictionary_path => "/etc/logstash/dictionary/severitycode.yml"
        }
        translate {
          field => "[junos_facilitycode]"
          destination => "[junos_facilityname]"
          dictionary_path => "/etc/logstash/dictionary/facilitycode.yml"
        }

        if "AUTHORIZATION" in [junos_facilityname] or "sshd|login" in [junos_procsname] {
          mutate {
            add_tag => "access_log"
          }
        }

        if "UI_LOGOUT_EVENT|UI_LOGIN_EVENT|UI_AUTH_EVENT|UI_CMDLINE_READ_LINE" in [junos_eventname] or "INTERACTIVE-COMMANDS" in [junos_facilityname] or "mgd" in [junos_procsname] {
          mutate {
            add_tag => "access_log"
          }
        }

        if "UI_JUNOSCRIPT_CMD" in [junos_eventname] {
          mutate { add_field => {"login_session" => "junos_script"} }
        }

        if "access_log" in [tags] {
          mutate { add_field => {"login_session" => "pending"} }
          grok {
              # TELNET/SSH FAILED
              match => { "junos_msg" =>
                [
                  "\[%{GREEDYDATA:} username=\"%{GREEDYDATA:login_user}\" source-address=\"%{IP:login_source}\"\] %{GREEDYDATA:}",
                  "\[%{GREEDYDATA} username=\"%{GREEDYDATA:login_user}\" source-address=\"%{IP:login_source}\"\]"
                ]
              }
              add_field => { "login_protocol" => "login failed" }
              add_tag => "login_trigger"
              tag_on_failure => []
          }

          grok {
              # TELNET OK
              match => { "junos_msg" => "\[%{GREEDYDATA:} username=\"%{GREEDYDATA:login_user}\" hostname=\"%{IP:login_source}\" tty-name=\"%{GREEDYDATA:client_mode}\"\] %{GREEDYDATA:}" }
              # SSH OK
              match => { "junos_msg" =>
                [
                  "\[%{DATA} username=\"%{GREEDYDATA:login_user}\" class-name=\"%{GREEDYDATA:class}\" local-peer=\"%{DATA}\" ssh-connection=\"%{IP:login_source} %{DATA}\" client-mode=\"%{GREEDYDATA:client_mode}\"\] %{GREEDYDATA:}",
                  "\[%{DATA} username=\"%{GREEDYDATA:login_user}\" class-name=\"%{GREEDYDATA:class}\" local-peer=\"%{DATA}\" ssh-connection=\"%{IP:login_source} %{DATA}\" client-mode=\"%{GREEDYDATA:client_mode}\"\]"
                ]
              }
              # Junoscript
              match => { "junos_msg" => "\[%{DATA} username=\"%{GREEDYDATA:login_user}\" class-name=\"%{GREEDYDATA:class}\" local-peer=\"%{DATA}\" %{GREEDYDATA:} client-mode=\"(?<client_mode>\junoscript)\"\] %{GREEDYDATA:}" }
              add_tag => "login_trigger"
              tag_on_failure => []
          }

          grok {
              # TELNET/SSH COMMAND - Interacetive User
              match => {
                "junos_msg" => [
                  "\[%{GREEDYDATA:} username=\"%{GREEDYDATA:login_user}\" command=\"%{GREEDYDATA:junos_command}\"\] %{GREEDYDATA:}",
                  "\[%{GREEDYDATA:}\] User '%{GREEDYDATA:login_user}', command '%{GREEDYDATA:junos_command}'",
                  "\[%{GREEDYDATA} username=\"%{GREEDYDATA:login_user}\" command=\"%{GREEDYDATA:junos_command}\"\]"
                  ]
                }
              # match => { "junos_msg" => "\[%{GREEDYDATA:}\] User '%{GREEDYDATA:login_user}', command '%{GREEDYDATA:junos_command}'" }
              add_tag => "interactive_user"
              tag_on_failure => []
          }

          grok {
              # NETCONF COMMAND - NETCONF User
              match => { "junos_msg" => "\[%{GREEDYDATA:}\] User '%{GREEDYDATA:login_user}' used NETCONF client to run command '%{GREEDYDATA:junos_command}'" }
              match => { "junos_msg" => "\[%{GREEDYDATA:}\] User '%{GREEDYDATA:login_user}', command 'xml-mode netconf need-trailer '" }
              match => { "junos_msg" => "\[%{GREEDYDATA:}\] User '%{GREEDYDATA:login_user}', command 'command rpc rpc command start shell command %{GREEDYDATA:}" }
              add_tag => "netconf_user"
              add_field => { "client_mode" => "netconf" }
              tag_on_failure => []
          }

          translate {
            exact => true
            regex => true
            field => "[client_mode]"
            destination => "[login_protocol]"
            dictionary_path => "/etc/logstash/dictionary/client_mode.yml"
          }
        }

        date {
          match => [ "junos_time", "ISO8601" ]
        }

        if "USER" in [junos_facilityname] and "smid" in [junos_procsname] and "WARNING" in [junos_severityname] {
          if "watermark" in [junos_msg] {
            mutate {
              add_tag => "alert_watermark"
            }
          }
        }
      }
      # if ["message"] {
      mutate {
          remove_field => [ "message" ]
        }
      # }
    }


    output {
      # if "junos_log" in [tags] or "access_log" in [tags] or "interactive_user" in [tags] or "netconf_user" in [tags] or "login_trigger" in [tags] {
      # if "junos_log" in [tags] and "alert_watermark" not in [tags] {
      if "junos_log" in [tags] and "alert_watermark" not in [tags] {
        elasticsearch {
          hosts => ["{{ join "\", \"https://" $newArray }}"]
          index => '{{ first  .Values.global.elasticsearch.index.name }}' # "junos-svtechlab-log"
          # cacert => "/etc/logstash/certs/NMS01.pem"
          user => '{{.Values.global.elasticsearch.adminUser.name}}' #{{.Values.global.user}}
          password => '{{.Values.global.elasticsearch.adminUser.pass}}'
          ssl_certificate_verification => false
        }
      }
      # stdout {codec => rubydebug}
      # stdout { codec => rubydebug { metadata => true } }

      if "_grokparsefailure" in [tags] {
        file { path => "/var/log/logstash/login_failed_onlinelog_events-%{+YYYY-MM}" }
      }
    }
################### End of svtech-lab device management pipeline config ###################


################### offline log uploaded from rundeck pipeline config ###################
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: offline-log
data:
  offline-log.conf: |
    input {
      beats {
        port => 5555
        tags => junos_offlog
        id => junos_offlog
        include_codec_tag => false
      }
    }

    filter {
      if "junos_offlog" in [fields][type] {
      # if "junos_offlog" in [type] {
        mutate {
          remove_field => ["host"]
          add_field => [ "[indexed_at]", "%{@timestamp}" ]
        }

        grok {
          pattern_definitions => {
            "LOG_DATA_NAME" => "[a-zA-Z0-9\_\-\.\:]{1,}"
            # "INDEX_NAME" => "[a-zA-Z]{1,}"
          }
          match => {
            "[log][file][path]" => "/var/tmp/index_syslog/%{LOG_DATA_NAME:[@metadata][offlog_suffix]}/%{LOG_DATA_NAME:[@metadata][offlog_junos_hostname]}/%{LOG_DATA_NAME:[log][file][name]}"
            # "[log][file][path]" => "/var/tmp/index_syslog/%{INDEX_NAME:[@metadata][index_name]}"
          }
        }

        grok {
          pattern_definitions => {
            "INDEX_NAME" => "[a-zA-Z0-9\_\-\.]{1,}"
          }
          match => {
            "[@metadata][offlog_suffix]" => "%{INDEX_NAME:[@metadata][index_name]}_"
            # "[log][file][path]" => "/var/tmp/index_syslog/%{INDEX_NAME:[@metadata][index_name]}"
          }
        }

        grok {
          pattern_definitions => {
            "ZONE" => "[a-z]{1,}"
          }
          match => {
            "[@metadata][offlog_suffix]" => "upload_%{ZONE:[@metadata][zone]}_"
          }
        }

        translate {
          field => "[@metadata][zone]"
          destination => "[@metadata][zone]"
          dictionary_path => "/etc/logstash/dictionary/timezone.yml"
        }

        mutate {
          add_tag => "%{[@metadata][index_name]}"
          # add_tag => "%{[@metadata][zone]}"
        }

        if [message] =~ /last message repeated \d+ time/ {
            drop {}
        }

        if [message] =~ /logfile turned over due to size/ {
            drop {}
        }

        # PARSE SRTUCTURE OFFLOG FILE
        if [message] =~ /\<([0-9]+)\>1/ {
          mutate {
            add_tag => "structured_log"
          }
          grok {
            match => {
              "message" => "<%{PRIORITYCODE:junos_priocode}>1 %{TIMESTAMP_ISO8601:junos_time} %{JUNHOSTNAME:junos_hostname} (%{PROCESSNAME:junos_procsname}|\-) (%{PROCESSID:junos_procsid}|\-) (%{EVENTNAME:junos_eventname}|\-) %{MESSAGE:junos_msg}"
            }
            patterns_dir => ["/etc/logstash/patterns"]
            patterns_files_glob => "structured_log"
          }
          mutate {
            convert => { "junos_priocode" => "integer" }
          }
          ruby {
            code => 'event.set("junos_facilitycode", event.get("junos_priocode")/8)'
          }
          ruby {
            code => 'event.set("junos_severitycode", event.get("junos_priocode")%8)'
          }
          translate {
            field => "[junos_severitycode]"
            destination => "[junos_severityname]"
            dictionary_path => "/etc/logstash/dictionary/severitycode.yml"
          }
          translate {
            field => "[junos_facilitycode]"
            destination => "[junos_facilityname]"
            dictionary_path => "/etc/logstash/dictionary/facilitycode.yml"
          }
        }

        # PARSE EXPLICIT PRIORITY OFFLOG FILE
        else if [message] =~ /\%([A-Z]+)\-([0-9]+)/ {
          mutate {
            add_tag => "junos_offlog_explicit_priority"
          }
          grok {
            match => {
              "message" => "(%{DATESTAMP_FULL:junos_time}|%{DATESTAMP_NOTYEAR:junos_time})  %{JUNHOSTNAME:junos_hostname} ((%{PROCESSNAME:junos_procsname}\[%{PROCESSID:junos_procsid}\]\:)|(%{PROCESSNAME:junos_procsname}\:)|(\:)) ((\%%{FACILITYNAME:junos_facilityname}\-%{SEVERITYCODE:junos_severitycode}\-%{EVENTNAME:junos_eventname}\:)|(\%%{FACILITYNAME:junos_facilityname}\-%{SEVERITYCODE:junos_severitycode}\:)|(\%%{FACILITYNAME:junos_facilityname}\-%{SEVERITYCODE:junos_severitycode}\-\:)) %{MESSAGE:junos_msg}"
            }
            patterns_dir => ["/etc/logstash/patterns"]
            patterns_files_glob => "junos_offlog_explicit_priority"
            remove_tag => [ "_grokparsefailure" ]
          }
        }

        # PARSE UNSTRUCTURE OFFLOG FILE
        else {
          mutate {
            remove_tag => ["junos_offlog_explicit_priority"]
            add_tag => "junos_offlog_unstructured_log"
          }
          # PARSE CHASSISD OFFLOG FILE - UNSTRUCTURE LOG
          if [log][file][name] =~ /\_chassisd/{
            grok {
              match => {
                "message" => "(%{DATESTAMP_FULL:junos_time}|%{DATESTAMP_NOTYEAR:junos_time}) %{GREEDYDATA:junos_msg}"
              }
              patterns_dir => ["/etc/logstash/patterns"]
              patterns_files_glob => "junos_offlog_unstructured_log"
              remove_tag => [ "_grokparsefailure" ]
            }
            mutate {
              add_field => { "junos_facilityname" => "CHASSISD" }
              add_field => { "junos_hostname" => "[@metadata][offlog_junos_hostname]" }
            }
          }
          # PARSE ANOTHER OFFLOG FILES - UNSTRUCTURE LOG
          else if [log][file][name] !~ /\_chassisd/ {
            grok {
              match => {
                "message" => [
                  "(%{DATESTAMP_FULL:junos_time}|%{DATESTAMP_NOTYEAR:junos_time})  (%{JUNHOSTNAME:junos_hostname} | )((%{PROCESSNAME:junos_procsname}\[%{PROCESSID:junos_procsid}\]\:)|(%{PROCESSNAME:junos_procsname}\:)|(%{PROCESSNAME:junos_procsname})) ((%{EVENTNAME:junos_eventname}\: %{MESSAGE:junos_msg})|%{MESSAGE:junos_msg})",
                  "(%{DATESTAMP_FULL:junos_time}|%{DATESTAMP_NOTYEAR:junos_time})  %{JUNHOSTNAME:junos_hostname} ((%{PROCESSNAME:junos_procsname}\[%{PROCESSID:junos_procsid}\]\:)|(%{PROCESSNAME:junos_procsname}\:)|(\:)) ((\%%{FACILITYNAME:junos_facilityname}\-%{SEVERITYCODE:junos_severitycode}\-%{EVENTNAME:junos_eventname}\:)|(\%%{FACILITYNAME:junos_facilityname}\-%{SEVERITYCODE:junos_severitycode}\:)|(\%%{FACILITYNAME:junos_facilityname}\-%{SEVERITYCODE:junos_severitycode}\-\:)) %{MESSAGE:junos_msg}"
                ]
              }
              patterns_dir => ["/etc/logstash/patterns"]
              patterns_files_glob => "junos_offlog_unstructured_log"
              remove_tag => [ "_grokparsefailure" ]
            }
            if "_grokparsefailure" in [tags] {
              ### BEGIN: Pattern fpc\d+ OR PFE\d+ exist AND pfed\: or pfe\: exists
              grok {
                match => { "message" => [ "(%{DATESTAMP_FULL:junos_time}|%{DATESTAMP_NOTYEAR:junos_time})  %{JUNHOSTNAME:junos_hostname} (%{PROCESSNAME:junos_procsname}\: )?%{FPCNAME:junos_fpcname} %{GREEDYDATA:junos_msg}" ] }
                patterns_dir => ["/etc/logstash/patterns"]
                patterns_files_glob => "junos_offlog_unstructured_log"
                add_field => {
                  "junos_facilityname" => "PFE"
                  "junos_procsname" => "pfed"
                }
                remove_tag => [ "_grokparsefailure" ]
              }
              ### END: Pattern fpc\d+ OR PFE\d+ exist AND pfed\: or pfe\: exists
            }
          }
        }

        date {
          match => [ "junos_time", "MMM dd HH:mm:ss.SSS yyyy", "MMM  d HH:mm:ss.SSS yyyy","MMM dd HH:mm:ss yyyy", "MMM  d HH:mm:ss yyyy", "ISO8601", "MMM dd HH:mm:ss", "MMM  d HH:mm:ss", "MMM  d HH:mm:ss.SSS yyyy", "MMM dd HH:mm:ss.SSS"]
          target => "junos_time"
          timezone => "%{[@metadata][zone]}"
        }
        # date { match => [ "indexed_at", "MMM dd HH:mm:ss.SSS yyy", "MMM  d HH:mm:ss.SSS yyy","MMM dd HH:mm:ss yyy", "MMM  d HH:mm:ss yyy", "ISO8601", "MMM dd HH:mm:ss", "MMM  d HH:mm:ss" ] }

        mutate {
          # we use a "temporal" field with a predefined arbitrary known value that
          add_field => { "[@metadata][junos_eventname_check]" => "unknown arbitrary value" }
          add_field => { "[@metadata][junos_severitycode_check]" => "unknown arbitrary value" }
          # If the field doesn't exist, copy is not executed.
          copy => { "junos_eventname" => "[@metadata][junos_eventname_check]" }
          copy => { "junos_severitycode" => "[@metadata][junos_severitycode_check]" }
        }
        if [@metadata][junos_eventname_check] != "unknown arbitrary value" {
          translate {
            field => "[junos_eventname]"
            destination => "[junos_severityname]"
            dictionary_path => "/etc/logstash/dictionary/flat_severity.yml"
            refresh_interval => 1
          }
          translate {
            field => "[junos_eventname]"
            destination => "[junos_facilityname]"
            dictionary_path => "/etc/logstash/dictionary/flat_facility.yml"
            refresh_interval => 1
          }
          translate {
            field => "[junos_eventname]"
            destination => "[junos_typename]"
            dictionary_path => "/etc/logstash/dictionary/flat_type.yml"
            refresh_interval => 1
          }
          # translate {
          #   field => "[junos_eventname]"
          #   destination => "[junos_severityname]"
          #   dictionary_path => "/etc/logstash/dictionary/flat_severity.yml"
          #   refresh_interval => 1
          # }
        }
        else if [@metadata][junos_severitycode_check] != "unknown arbitrary value" {
          translate {
            field => "[junos_severitycode]"
            destination => "[junos_severityname]"
            dictionary_path => "/etc/logstash/dictionary/severitycode.yml"
            refresh_interval => 1
          }
        }

        if "AUTHORIZATION" in [junos_facilityname] or "sshd|login" in [junos_procsname] {
          mutate {
            add_tag => "access_log"
          }
        }

        if "UI_LOGOUT_EVENT|UI_LOGIN_EVENT|UI_AUTH_EVENT|UI_CMDLINE_READ_LINE" in [junos_eventname] or "INTERACTIVE-COMMANDS" in [junos_facilityname] or "mgd" in [junos_procsname] {
          mutate {
            add_tag => "access_log"
          }
        }

        if "UI_JUNOSCRIPT_CMD" in [junos_eventname] {
          mutate { add_field => { "login_session" => "junos_script"} }
        }

        if "access_log" in [tags] {
          mutate { add_field => { "login_session" => "pending"} }
          grok {
            # TELNET/SSH FAILED
            match => {
              "junos_msg" => [
                "\[%{GREEDYDATA:} username=\"%{GREEDYDATA:login_user}\" source-address=\"%{IP:login_source}\"\] %{GREEDYDATA:}",
                "Login failed for user %{GREEDYDATA:login_user} from host %{IP:login_source}"
              ]
            }
            add_field => { "login_protocol" => "login failed" }
            add_tag => "login_trigger"
            tag_on_failure => []
          }

          grok {
            # TELNET, SSh, Junoscript OK
            match => {
              "junos_msg" => [
                # User '%{GREEDYDATA:login_user}' login, class '%{GREEDYDATA:class}' \[%{PROCESSID:junos_procsid}\]%{GREEDYDATA}, ssh-connection ((?:(\'%{IP:login_source} %{GREEDYDATA} %{IP:junos_host} %{INT:port}\'))?|(?:(\'%{GREEDYDATA:login_source}\'))?), client-mode \'%{GREEDYDATA:client_mode}\'
                "User '%{GREEDYDATA:login_user}' login, class '%{GREEDYDATA:class}' \[%{PROCESSID:junos_procsid}\]%{GREEDYDATA}, ssh-connection ((?:(\'%{IP:login_source} %{GREEDYDATA} %{IP:junos_host} %{INT:login_port}\'))?), client-mode \'%{GREEDYDATA:client_mode}\'",
                "User %{GREEDYDATA:login_user} logged in from host %{GREEDYDATA:login_source} on device %{GREEDYDATA:client_mode}"
              ]
            }
            patterns_dir => ["/etc/logstash/patterns"]
            patterns_files_glob => "junos_offlog_unstructured_log"
            add_tag => "login_trigger"
            tag_on_failure => []
          }

          if "login_trigger" in [tags] {
            if ![login_source] {
              mutate {
                gsub => ["client_mode", "cli", "tty"]
              }
            }
          }

          grok {
            # TELNET/SSH COMMAND - Interacetive User
            match => { "junos_msg" => "User '%{GREEDYDATA:login_user}', command '%{GREEDYDATA:junos_command}'" }
            add_tag => "interactive_user"
            tag_on_failure => []
          }

          grok {
            # NETCONF COMMAND - NETCONF User
            match => { "junos_msg" => "User '%{GREEDYDATA:login_user}' used NETCONF client to run command '%{GREEDYDATA:junos_command}'" }
            match => { "junos_msg" => "User '%{GREEDYDATA:login_user}', command 'xml-mode netconf need-trailer '" }
            match => { "junos_msg" => "User '%{GREEDYDATA:login_user}', command 'command rpc rpc command start shell command %{GREEDYDATA:}" }
            add_tag => "netconf_user"
            add_field => { "client_mode" => "netconf" }
            tag_on_failure => []
          }

          translate {
            exact => true
            regex => true
            field => "[client_mode]"
            destination => "[login_protocol]"
            dictionary_path => "/etc/logstash/dictionary/client_mode.yml"
          }
        }

        mutate {
          # CONVERT OFFLINE FILENAME TO JUNOS_HOSTNAME
          gsub => [ "[@metadata][offlog_junos_hostname]", "_RE\d*", "" ]
          copy => { "[@metadata][offlog_junos_hostname]" => "[junos_hostname]" }
        }


    #    mutate { add_field => { "[@metadata][dest]" => "junos_offlog-%{suffix}" } }
    #    }
      }
    }

    output {
      if "junos_offlog" in [fields][type] or "access_log" in [tags] or "interactive_user" in [tags] or "netconf_user" in [tags] or "login_trigger" in [tags] {
      # if "junos_offlog" in [fields][type] {
        elasticsearch {
          hosts => ["{{ join "\", \"https://" $newArray }}"]
          index => "offline-log"
          # index => "%{[@metadata][index_name]}"
          # cacert => "/etc/logstash/certs/NMS01.pem"
          user => '{{.Values.global.elasticsearch.adminUser.name}}' #{{.Values.global.user}}
          password => '{{.Values.global.elasticsearch.adminUser.pass}}'
          ssl_certificate_verification => false
        }
      }

      # stdout {codec => rubydebug}
      if "_grokparsefailure" in [tags] {
        file { path => "/tmp/jun-offline-logstash_failed_parse_events-%{+YYYY-MM}" }
      }
    }
################### End of offline log uploaded from rundeck pipeline config ###################

################### movitel MX devices log stream pipeline config ###################
---
# apiVersion: v1
# kind: ConfigMap
# metadata:
#   name: movitel-online-log
# data:
#   movitel.conf: |
#     input {
#       http {
#         port => 9000
#         additional_codecs => { "application/json" => "json_lines" }
#       }
#     }
#     filter {
#       # mutate {
#       #   remove_field => [ "headers", "user_agent", "url", "port", "domain", "http", "mime_type", "host", "@version"]
#       # }
#       mutate {
#         remove_field => [ "headers"]
#       }


#       if [log][file][name][1] {
#         mutate {
#           remove_field => "[log][file][name][1]"
#         }
#       }
#     }
#     output {
#       # stdout {codec => rubydebug}
#       # if "junos_offlog" in [fields][type] or "access_log" in [tags] or "interactive_user" in [tags] or "netconf_user" in [tags] or "login_trigger" in [tags] {
#       if "junos_log" in [tags] and "alert_watermark" not in [tags] {
#         elasticsearch {
#           hosts => ["{{ join "\", \"https://" $newArray }}"]
#           index => "junos-log"
#           # cacert => "/etc/logstash/certs/NMS01.pem"
#           user => {{.Values.global.elasticsearch.adminUser.name}} #{{.Values.global.user}}
#           password => '{{.Values.global.elasticsearch.adminUser.pass}}'
#           ssl_certificate_verification => false
#         }
#       }
#     }
################### End of movitel MX devices log stream pipeline config ###################


